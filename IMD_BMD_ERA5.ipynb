{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "722b2451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.core.options.set_options at 0x7052ee9ef050>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 1 — Imports & basic config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "plt.rcParams.update({\"figure.dpi\": 140})\n",
    "xr.set_options(keep_attrs=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e833248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 — Helpers (normalization, grid, time, masking)\n",
    "\n",
    "def _to_0360(obj):\n",
    "    if \"longitude\" in obj.coords:\n",
    "        lon = obj[\"longitude\"]\n",
    "        try:\n",
    "            if float(lon.min()) < 0:\n",
    "                obj = obj.assign_coords(longitude=(lon % 360))\n",
    "        except Exception:\n",
    "            pass\n",
    "        obj = obj.sortby(\"longitude\")\n",
    "    return obj\n",
    "\n",
    "def _ensure_lat_asc(obj):\n",
    "    if \"latitude\" in obj.coords:\n",
    "        lat = obj[\"latitude\"].values\n",
    "        if len(lat) > 1 and lat[0] > lat[-1]:\n",
    "            obj = obj.sortby(\"latitude\")\n",
    "    return obj\n",
    "\n",
    "def _normalize_precip(da):\n",
    "    units = (da.attrs.get(\"units\") or da.attrs.get(\"unit\") or \"\").lower()\n",
    "    out = da\n",
    "    if units in [\"m\", \"meter\", \"metre\", \"m of water equivalent\"]:\n",
    "        out = out * 1000.0\n",
    "    out.attrs[\"units\"] = \"mm/day\"\n",
    "    return out\n",
    "\n",
    "def _normalize_temp(da):\n",
    "    units = (da.attrs.get(\"units\") or da.attrs.get(\"unit\") or \"\").lower()\n",
    "    out = da\n",
    "    if units in [\"k\", \"kelvin\"]:\n",
    "        out = out - 273.15\n",
    "        out.attrs[\"units\"] = \"°C\"\n",
    "    elif units in [\"degc\", \"c\", \"°c\"]:\n",
    "        out.attrs[\"units\"] = \"°C\"\n",
    "    return out\n",
    "\n",
    "def _coerce_time(da):\n",
    "    if \"time\" in da.dims:\n",
    "        return da\n",
    "    try:\n",
    "        dec = xr.decode_cf(da.to_dataset(name=\"_tmp\")).to_array(\"_tmp\")\n",
    "        if \"time\" in dec.dims:\n",
    "            return dec\n",
    "    except Exception:\n",
    "        pass\n",
    "    return da\n",
    "\n",
    "def _align_to_truth_grid(src: xr.DataArray, truth: xr.DataArray) -> xr.DataArray:\n",
    "    s = _ensure_lat_asc(_to_0360(src))\n",
    "    t = _ensure_lat_asc(_to_0360(truth))\n",
    "    # identical labels?\n",
    "    try:\n",
    "        if (np.array_equal(s.latitude.values, t.latitude.values) and\n",
    "            np.array_equal(s.longitude.values, t.longitude.values)):\n",
    "            return s\n",
    "    except Exception:\n",
    "        pass\n",
    "    # reindex with tolerance first\n",
    "    try:\n",
    "        return s.reindex_like(t, method=\"nearest\", tolerance={\"latitude\":0.125, \"longitude\":0.125})\n",
    "    except Exception:\n",
    "        pass\n",
    "    # fallback interp\n",
    "    s2 = s.sortby([\"latitude\",\"longitude\"])\n",
    "    t2 = t.sortby([\"latitude\",\"longitude\"])\n",
    "    return s2.interp(latitude=t2[\"latitude\"], longitude=t2[\"longitude\"], method=\"nearest\")\n",
    "\n",
    "def _time_intersect(*arrs):\n",
    "    t0 = max([np.datetime64(a.time.min().values) for a in arrs])\n",
    "    t1 = min([np.datetime64(a.time.max().values) for a in arrs])\n",
    "    return [a.sel(time=slice(t0, t1)) for a in arrs]\n",
    "\n",
    "def _land_mask_from_truth(truth_da: xr.DataArray) -> xr.DataArray:\n",
    "    \"\"\"mask (True) where truth has *any* finite value over the window → removes ocean/out-of-country.\"\"\"\n",
    "    return xr.ufuncs.isfinite(truth_da).any(\"time\")\n",
    "\n",
    "def _rmse_series(pred, truth):\n",
    "    se = (pred - truth)**2\n",
    "    return np.sqrt(se.mean(dim=[d for d in [\"latitude\",\"longitude\"] if d in se.dims], skipna=True)).squeeze()\n",
    "\n",
    "def _mae_series(pred, truth):\n",
    "    ae = (pred - truth).abs()\n",
    "    return ae.mean(dim=[d for d in [\"latitude\",\"longitude\"] if d in ae.dims], skipna=True).squeeze()\n",
    "\n",
    "def _bias_map(pred, truth):\n",
    "    # simple time mean of (pred - truth), expects (time, lat, lon)\n",
    "    return (pred - truth).mean(\"time\", skipna=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d68c573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_step(output_state, runcount):\n",
    "    data_vars = {}\n",
    "    logging.info(f\"Processing step {runcount}\")\n",
    "    for field in output_state['fields']:\n",
    "        values = (TFM_N320_LATLON * output_state['fields'][field].reshape(-1,1)).reshape(721,1440)\n",
    "        data_vars[field] = ([\"lat\", \"lon\"], values.astype(np.float32))\n",
    "\n",
    "    step_ds = xr.Dataset(\n",
    "        data_vars,\n",
    "        coords={\"lat\": LATITUDES, \"lon\": LONGITUDES},\n",
    "    )\n",
    "    step_ds = step_ds.expand_dims('step')\n",
    "    step_ds['step'] = [int(runcount)]\n",
    "    return step_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7857e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- PATCHED run_inference: include save_vars in output filename ----\n",
    "def run_inference(init_date=None, lead_time=360, save_vars=None):\n",
    "\n",
    "    if lead_time < 6 or lead_time % 6 != 0:\n",
    "        raise ValueError(\"Lead time must be a multiple of 6 hours and at least 6 hours.\")\n",
    "\n",
    "    if save_vars is None and lead_time > 120:\n",
    "        logging.warning(\"Running this model for more than 120 steps and saving all variables is not recommended.\")\n",
    "\n",
    "    ic_src = \"IFS\" if init_date is None else \"ERA5\"\n",
    "\n",
    "    # NEW: encode which vars are saved so different runs don't overwrite each other\n",
    "    vars_tag = \"ALL\" if save_vars is None else \"-\".join(save_vars)\n",
    "    save_path = f\"{OUTPUT_STATE_PATH}/init_{ic_src}_{init_date.strftime('%Y%m%dT%H')}_lead_{lead_time}_vars_{vars_tag}.zarr\"\n",
    "\n",
    "    if os.path.exists(save_path):\n",
    "        logging.info(f\"Output file {save_path} already exists. Skipping inference.\")\n",
    "        logging.info(\"Loading existing dataset...\")\n",
    "        return xr.open_zarr(save_path)\n",
    "\n",
    "    # build input state\n",
    "    if ic_src == \"IFS\":\n",
    "        input_state = get_latest_IFS_data()\n",
    "    else:\n",
    "        input_state = get_ERA5(init_date)\n",
    "\n",
    "    runner = SimpleRunner(CHECKPOINT, device=\"cuda\")\n",
    "    current_step = 0\n",
    "    start_time = time.perf_counter()\n",
    "    print(\"Starting the inference session...\")\n",
    "    current_step_time = time.perf_counter()\n",
    "    states = []\n",
    "    for state in runner.run(input_state=input_state, lead_time=lead_time):\n",
    "        print_state(state)\n",
    "        current_step += 6\n",
    "        if save_vars is None:\n",
    "            processed_state = process_step(state, current_step)\n",
    "        else:\n",
    "            selected_data = {\n",
    "                'date': state['date'],\n",
    "                'fields': {var: state['fields'][var] for var in save_vars},\n",
    "                'latitudes': state['latitudes'],\n",
    "                'longitudes': state['longitudes'],\n",
    "            }\n",
    "            processed_state = process_step(selected_data, current_step)\n",
    "        states.append(processed_state)\n",
    "        logging.info(f\"Step {current_step} completed.\")\n",
    "        step_time = time.perf_counter()\n",
    "        logging.info(f\"Time taken for step {current_step}: {step_time - current_step_time:.2f} s.\")\n",
    "        current_step_time = step_time\n",
    "\n",
    "    logging.info(\"Inference session completed.\")\n",
    "    logging.info(f\"Total time: {time.perf_counter() - start_time:.2f} s.\")\n",
    "\n",
    "    logging.info(\"Concatenating all steps into a single dataset.\")\n",
    "    ds = xr.concat(states, dim='step')\n",
    "    del states\n",
    "    ds = ds.expand_dims(\"time\")\n",
    "    ds[\"time\"] = [pd.to_datetime(input_state['date'])]\n",
    "\n",
    "    logging.info(f\"Saving output dataset to {save_path}\")\n",
    "    ds.to_zarr(save_path, mode='w', zarr_format=2)\n",
    "\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82a14903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Patched _rmse_mae_series (uses np.abs). Re-run your time-series now.\n"
     ]
    }
   ],
   "source": [
    "# PATCH: replace _rmse_mae_series to avoid .abs() (use np.abs)\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "SPATIAL_DIMS = (\"latitude\", \"longitude\")\n",
    "\n",
    "def _rmse_mae_series(pred: xr.DataArray, truth: xr.DataArray):\n",
    "    \"\"\"\n",
    "    Inputs: pred, truth with dims (time, latitude, longitude),\n",
    "    already masked to the truth coverage.\n",
    "    Returns (rmse_ts, mae_ts) as 1D time series.\n",
    "    \"\"\"\n",
    "    # ensure numeric (some sources may be int)\n",
    "    diff = (pred - truth).astype(\"float32\")\n",
    "\n",
    "    se = diff ** 2\n",
    "    ae = np.abs(diff)                       # <-- key change\n",
    "\n",
    "    rmse_ts = se.mean([d for d in SPATIAL_DIMS if d in se.dims], skipna=True) ** 0.5\n",
    "    mae_ts  = ae.mean([d for d in SPATIAL_DIMS if d in ae.dims],  skipna=True)\n",
    "\n",
    "    return rmse_ts.squeeze(), mae_ts.squeeze()\n",
    "\n",
    "print(\"✅ Patched _rmse_mae_series (uses np.abs). Re-run your time-series now.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7914986d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453cdebd42ec4f9b849529af5fb2d981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='BMD (opt):', layout=Layout(width='95%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7732708538ab4a68b10c89afff68a867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='gs://aim4scale_training_25/ground_truth/era5_24hr.zarr', description='ERA5:', layout=Layout(width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a33cd18bb54295be4447c2fa15e19e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='gs://aim4scale_training_25/ground_truth/IMERG_0p25_2000_2025.zarr', description='IMERG:', layout=L…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3594138e1e1f430e993c265cc3852e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='gs://aim4scale_training_25/ground_truth/IMD_rainfall_0p25.zarr', description='IMD:', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bde97298dd545de800e659320eb2e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Load datasets', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb3d42267584ee6bb3af2de50c72028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Cell 0: Load datasets via widgets (BMD optional) ---\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def _open_any(path: str):\n",
    "    if path.endswith(\".zarr\"):\n",
    "        return xr.open_zarr(path)\n",
    "    return xr.open_dataset(path)\n",
    "\n",
    "# Known defaults (edit if you have different ERA5/IMERG/IMD)\n",
    "DEFAULT_ERA5  = \"gs://aim4scale_training_25/ground_truth/era5_24hr.zarr\"\n",
    "DEFAULT_IMERG = \"gs://aim4scale_training_25/ground_truth/IMERG_0p25_2000_2025.zarr\"\n",
    "DEFAULT_IMD   = \"gs://aim4scale_training_25/ground_truth/IMD_rainfall_0p25.zarr\"\n",
    "DEFAULT_BMD = \"gs://aim4scale_training_25/ground_truth/BMD_daily_combined_0p25.zarr\"\n",
    "\n",
    "bmd_txt   = widgets.Text(value=DEFAULT_BMD,      description=\"BMD:\",        layout=widgets.Layout(width=\"95%\"))\n",
    "era5_txt  = widgets.Text(value=DEFAULT_ERA5,     description=\"ERA5:\",       layout=widgets.Layout(width=\"95%\"))\n",
    "imerg_txt = widgets.Text(value=DEFAULT_IMERG,    description=\"IMERG:\",      layout=widgets.Layout(width=\"95%\"))\n",
    "imd_txt   = widgets.Text(value=DEFAULT_IMD,      description=\"IMD:\",        layout=widgets.Layout(width=\"95%\"))\n",
    "btn_load  = widgets.Button(description=\"Load datasets\", button_style=\"primary\")\n",
    "out_load  = widgets.Output()\n",
    "display(bmd_txt, era5_txt, imerg_txt, imd_txt, btn_load, out_load)\n",
    "\n",
    "# Globals created by this cell:\n",
    "ds_bmd = None\n",
    "ds_era5 = None\n",
    "ds_imerg = None\n",
    "ds_imd = None\n",
    "\n",
    "def _summ(ds, name):\n",
    "    vars_ = list(ds.data_vars)[:6]\n",
    "    tcoord = \"valid_time\" if \"valid_time\" in ds.coords else (\"time\" if \"time\" in ds.coords else None)\n",
    "    tspan = \"—\"\n",
    "    if tcoord:\n",
    "        tspan = f\"{pd.to_datetime(str(ds[tcoord].values.min())).date()} … {pd.to_datetime(str(ds[tcoord].values.max())).date()}\"\n",
    "    return f\"**{name}**  \\nvars → {vars_} | sizes → {dict(ds.sizes)}  \\n\" + (f\"time → {tspan}\" if tcoord else \"\")\n",
    "\n",
    "def _try_open(label, path):\n",
    "    p = path.strip()\n",
    "    if p == \"\":\n",
    "        return None, f\"**{label}**: (skipped — empty path)\"\n",
    "    try:\n",
    "        ds = _open_any(p)\n",
    "        return ds, _summ(ds, label)\n",
    "    except Exception as e:\n",
    "        return None, f\"**{label}**: ❌ load failed → `{e}`\"\n",
    "\n",
    "def _on_load(_):\n",
    "    global ds_bmd, ds_era5, ds_imerg, ds_imd\n",
    "    with out_load:\n",
    "        out_load.clear_output()\n",
    "        ds_bmd,   msg_bmd   = _try_open(\"BMD\",   bmd_txt.value)\n",
    "        ds_era5,  msg_era5  = _try_open(\"ERA5\",  era5_txt.value)\n",
    "        ds_imerg, msg_imerg = _try_open(\"IMERG\", imerg_txt.value)\n",
    "        ds_imd,   msg_imd   = _try_open(\"IMD\",   imd_txt.value)\n",
    "\n",
    "        display(Markdown(\"### Load summary\"))\n",
    "        display(Markdown(msg_bmd))\n",
    "        display(Markdown(msg_era5))\n",
    "        display(Markdown(msg_imerg))\n",
    "        display(Markdown(msg_imd))\n",
    "\n",
    "        ready = (ds_era5 is not None) and (ds_imerg is not None or ds_bmd is not None or ds_imd is not None)\n",
    "        if ready:\n",
    "            display(Markdown(\"✅ **Datasets ready.** Now run the next cells.\"))\n",
    "        else:\n",
    "            display(Markdown(\"⚠️ **Please load at least ERA5 plus one of BMD/IMERG/IMD.**\"))\n",
    "\n",
    "btn_load.on_click(_on_load)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99832a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**ERA5 merged dataset**  \n",
       "vars: total_precipitation_24hr, tavg, tmax, tmin | sizes: {'time': 67208, 'latitude': 721, 'longitude': 1440} | time: 1979-01-01 … 2024-12-31"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- ERA5 loader/merger: combine precip + temperature daily into a single ds_era5 ---\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Adjust paths if yours are different\n",
    "PATH_ERA5_TP  = \"gs://aim4scale_training_25/ground_truth/era5_24hr.zarr\"            # precip (total_precipitation_24hr)\n",
    "PATH_ERA5_T2M = \"gs://aim4scale_training_25/ground_truth/era5_t2m_1D_1981_2024.zarr\" # tavg, tmax, tmin\n",
    "\n",
    "def _open_any(path: str):\n",
    "    return xr.open_zarr(path) if path.endswith(\".zarr\") else xr.open_dataset(path)\n",
    "\n",
    "def _to_0360(ds):\n",
    "    if \"longitude\" in ds.coords:\n",
    "        lon = ds[\"longitude\"]\n",
    "        try:\n",
    "            if float(lon.min()) < 0:\n",
    "                ds = ds.assign_coords(longitude=(lon % 360))\n",
    "        except Exception:\n",
    "            pass\n",
    "        ds = ds.sortby(\"longitude\")\n",
    "    return ds\n",
    "\n",
    "def _lat_asc(ds):\n",
    "    if \"latitude\" in ds.coords:\n",
    "        lat = ds[\"latitude\"].values\n",
    "        if len(lat) > 1 and lat[0] > lat[-1]:\n",
    "            ds = ds.sortby(\"latitude\")\n",
    "    return ds\n",
    "\n",
    "def _prep(ds):\n",
    "    return _lat_asc(_to_0360(ds))\n",
    "\n",
    "def _time_bounds(ds):\n",
    "    if \"time\" not in ds.coords:\n",
    "        return \"—\", \"—\"\n",
    "    # robust formatting that works even with cftime/dtypes\n",
    "    tmin = pd.to_datetime(str(ds.time.min().values)).date()\n",
    "    tmax = pd.to_datetime(str(ds.time.max().values)).date()\n",
    "    return str(tmin), str(tmax)\n",
    "\n",
    "# Load & normalize\n",
    "era5_tp  = _prep(_open_any(PATH_ERA5_TP))\n",
    "era5_t2m = _prep(_open_any(PATH_ERA5_T2M))\n",
    "\n",
    "# Merge (outer join along time so either side’s dates are included)\n",
    "ds_era5 = xr.merge([era5_tp, era5_t2m], compat=\"override\", join=\"outer\")\n",
    "\n",
    "# Keep only relevant variables if you want\n",
    "keep_vars = [v for v in [\"total_precipitation_24hr\", \"tavg\", \"tmax\", \"tmin\"] if v in ds_era5.data_vars]\n",
    "ds_era5 = ds_era5[keep_vars]\n",
    "\n",
    "# Summary\n",
    "vars_list = \", \".join(list(ds_era5.data_vars))\n",
    "t0, t1 = _time_bounds(ds_era5)\n",
    "summary = f\"vars: {vars_list} | sizes: {dict(ds_era5.sizes)} | time: {t0} … {t1}\"\n",
    "display(Markdown(\"**ERA5 merged dataset**  \\n\" + summary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9244ad24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Auto-detected variables (first alias match):**\n",
       "- **precip** → BMD=`total_precipitation_24hr` | ERA5=`total_precipitation_24hr` | IMERG=`total_precipitation_24hr`\n",
       "- **tavg** → BMD=`tavg` | ERA5=`tavg` | IMERG=`None`\n",
       "- **tmax** → BMD=`tmax` | ERA5=`tmax` | IMERG=`None`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**(Optional) Override detected variable names** — leave blank to keep auto:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65c244ee8414d258fd42692dda99b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='total_precipitation_24hr', description='BMD precip:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8387713d154f048050593d6ebdf99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='total_precipitation_24hr', description='ERA5 precip:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c3bf1d20be4528bec908d739d61c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='tavg', description='BMD tavg:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31512f2d6dc14405a209c7e95fd52481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='tavg', description='ERA5 tavg:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b856618ece4b348c29db159c2fbf96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='tmax', description='BMD tmax:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ced5b40a5394567aaa4449d8188c4c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='tmax', description='ERA5 tmax:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52efe648af204ffe863958d9b2ead439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Metric:', options=('RMSE', 'MAE'), value='RMSE')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c428a02dea4c188ad2b7946a2f8f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='2018-06-01', description='Start (YYYY-MM-DD):')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127c4516b2364a5c9369fc28727fb356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='2018-06-30', description='End   (YYYY-MM-DD):')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8936d056e2d49d3ae82cc90fdaa92ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Run ALL (BMD truth)', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70d3e2285ba49df98e801153d8c410b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === BMD truth vs ERA5 & IMERG — plot ALL variables (precip / tavg / tmax) ===\n",
    "import numpy as np, xarray as xr, matplotlib.pyplot as plt, ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "plt.rcParams.update({\"figure.dpi\": 120})\n",
    "\n",
    "# ---------------- helpers ----------------\n",
    "def _norm_precip_mm(da):\n",
    "    u = (da.attrs.get(\"units\") or da.attrs.get(\"unit\") or \"\").lower()\n",
    "    if u in [\"m\",\"meter\",\"metre\",\"m of water equivalent\"]:\n",
    "        da = da * 1000.0\n",
    "    # kg m-2 ≈ mm already\n",
    "    da.attrs[\"units\"] = \"mm\"\n",
    "    return da\n",
    "\n",
    "def _norm_temp_K(da):\n",
    "    u = (da.attrs.get(\"units\") or da.attrs.get(\"unit\") or \"\").lower()\n",
    "    if u in [\"c\",\"degc\",\"celsius\",\"°c\"]:\n",
    "        da = da + 273.15\n",
    "    da.attrs[\"units\"] = \"K\"\n",
    "    return da\n",
    "\n",
    "def _norm(var_key, da):\n",
    "    return _norm_precip_mm(da) if var_key == \"precip\" else _norm_temp_K(da)\n",
    "\n",
    "def _ensure_valid_time(da):\n",
    "    if \"valid_time\" in da.dims:\n",
    "        return da\n",
    "    if \"time\" in da.dims:\n",
    "        return da.rename({\"time\": \"valid_time\"})\n",
    "    dec = xr.decode_cf(da.to_dataset(name=\"_tmp\"), use_cftime=False).to_array(\"_tmp\")\n",
    "    if \"time\" in dec.dims:\n",
    "        return dec.rename({\"time\": \"valid_time\"})\n",
    "    raise ValueError(\"No time/valid_time dimension.\")\n",
    "\n",
    "def _align_to_truth(src, truth):\n",
    "    s = src.sortby([\"latitude\", \"longitude\"])\n",
    "    r = truth.sortby([\"latitude\", \"longitude\"])\n",
    "    try:\n",
    "        return s.reindex_like(\n",
    "            r, method=\"nearest\", tolerance={\"latitude\": 0.125, \"longitude\": 0.125}\n",
    "        )\n",
    "    except Exception:\n",
    "        return s.interp(latitude=r.latitude, longitude=r.longitude, method=\"nearest\")\n",
    "\n",
    "def _rmse_mae_series(pred, truth):\n",
    "    diff = (pred - truth).astype(\"float32\")\n",
    "    se = diff**2\n",
    "    ae = np.abs(diff)\n",
    "    rmse = se.mean([d for d in (\"latitude\",\"longitude\") if d in se.dims], skipna=True) ** 0.5\n",
    "    mae  = ae.mean([d for d in (\"latitude\",\"longitude\") if d in ae.dims],  skipna=True)\n",
    "    return rmse.squeeze(), mae.squeeze()\n",
    "\n",
    "def _mask_to_truth(truth, *others):\n",
    "    # mask oceans by \"ever finite\" on truth over the window\n",
    "    mask = xr.ufuncs.isfinite(truth).any(\"valid_time\")\n",
    "    outs = [truth.where(mask)] + [o.where(mask) for o in others]\n",
    "    return outs\n",
    "\n",
    "# ---------------- auto-detect concrete var names ----------------\n",
    "ALIASES = {\n",
    "    \"precip\": [\"total_precipitation_24hr\", \"tp_24h\", \"tp_daily\", \"precip\", \"rain\"],\n",
    "    \"tavg\":   [\"tavg\", \"t2m_mean\", \"t2m_daily_mean\", \"daily_mean_temperature\", \"tas_mean\", \"tmean\"],\n",
    "    \"tmax\":   [\"tmax\", \"t2m_max\", \"t2m_daily_max\", \"daily_max_temperature\", \"tasmax\", \"tmax_mean\"],\n",
    "}\n",
    "LABELS = {\"precip\": \"Precip (mm/day)\", \"tavg\": \"Temp avg (K)\", \"tmax\": \"Temp max (K)\"}\n",
    "\n",
    "def _first_present(ds, names):\n",
    "    if ds is None: \n",
    "        return None\n",
    "    for n in names:\n",
    "        if n in ds.data_vars:\n",
    "            return n\n",
    "    return None\n",
    "\n",
    "def _autoguess_mapping(ds_bmd, ds_era5, ds_imerg=None):\n",
    "    m = {}\n",
    "    lines = []\n",
    "    for key, aliases in ALIASES.items():\n",
    "        b = _first_present(ds_bmd,  aliases)\n",
    "        e = _first_present(ds_era5, aliases)\n",
    "        i = _first_present(ds_imerg, aliases) if ds_imerg is not None else None\n",
    "        m[key] = {\"bmd\": b, \"era5\": e, \"imerg\": i}\n",
    "        lines.append(f\"- **{key}** → BMD=`{b}` | ERA5=`{e}` | IMERG=`{i}`\")\n",
    "    return m, \"\\n\".join(lines)\n",
    "\n",
    "mapping, mapping_note = _autoguess_mapping(ds_bmd, ds_era5, ds_imerg if \"ds_imerg\" in globals() else None)\n",
    "display(Markdown(\"**Auto-detected variables (first alias match):**\\n\" + mapping_note))\n",
    "\n",
    "# Optional overrides\n",
    "txt_bmd_precip = widgets.Text(value=mapping[\"precip\"][\"bmd\"] or \"\", description=\"BMD precip:\")\n",
    "txt_era_precip = widgets.Text(value=mapping[\"precip\"][\"era5\"] or \"\", description=\"ERA5 precip:\")\n",
    "txt_bmd_tavg   = widgets.Text(value=mapping[\"tavg\"][\"bmd\"]   or \"\", description=\"BMD tavg:\")\n",
    "txt_era_tavg   = widgets.Text(value=mapping[\"tavg\"][\"era5\"]  or \"\", description=\"ERA5 tavg:\")\n",
    "txt_bmd_tmax   = widgets.Text(value=mapping[\"tmax\"][\"bmd\"]   or \"\", description=\"BMD tmax:\")\n",
    "txt_era_tmax   = widgets.Text(value=mapping[\"tmax\"][\"era5\"]  or \"\", description=\"ERA5 tmax:\")\n",
    "display(Markdown(\"**(Optional) Override detected variable names** — leave blank to keep auto:\"),\n",
    "        txt_bmd_precip, txt_era_precip, txt_bmd_tavg, txt_era_tavg, txt_bmd_tmax, txt_era_tmax)\n",
    "\n",
    "def _current_mapping():\n",
    "    # IMERG is optional; we only need BMD & ERA5 for a variable to be plottable\n",
    "    return {\n",
    "        \"precip\": {\"bmd\": txt_bmd_precip.value or mapping[\"precip\"][\"bmd\"],\n",
    "                   \"era5\": txt_era_precip.value or mapping[\"precip\"][\"era5\"],\n",
    "                   \"imerg\": mapping[\"precip\"][\"imerg\"]},\n",
    "        \"tavg\":   {\"bmd\": txt_bmd_tavg.value   or mapping[\"tavg\"][\"bmd\"],\n",
    "                   \"era5\": txt_era_tavg.value  or mapping[\"tavg\"][\"era5\"],\n",
    "                   \"imerg\": mapping[\"tavg\"][\"imerg\"]},\n",
    "        \"tmax\":   {\"bmd\": txt_bmd_tmax.value   or mapping[\"tmax\"][\"bmd\"],\n",
    "                   \"era5\": txt_era_tmax.value  or mapping[\"tmax\"][\"era5\"],\n",
    "                   \"imerg\": mapping[\"tmax\"][\"imerg\"]},\n",
    "    }\n",
    "\n",
    "def _plottable_vars(curmap):\n",
    "    # Only keep variables present in BOTH BMD and ERA5\n",
    "    out = []\n",
    "    for key in [\"precip\", \"tavg\", \"tmax\"]:\n",
    "        if curmap[key][\"bmd\"] and curmap[key][\"era5\"]:\n",
    "            out.append(key)\n",
    "    return out\n",
    "\n",
    "# ---------------- UI ----------------\n",
    "metric_dd = widgets.Dropdown(options=[\"RMSE\",\"MAE\"], description=\"Metric:\", value=\"RMSE\")\n",
    "t0_txt    = widgets.Text(value=\"2018-06-01\", description=\"Start (YYYY-MM-DD):\")\n",
    "t1_txt    = widgets.Text(value=\"2018-06-30\", description=\"End   (YYYY-MM-DD):\")\n",
    "btn_run   = widgets.Button(description=\"Run ALL (BMD truth)\", button_style=\"success\")\n",
    "out_all   = widgets.Output()\n",
    "display(metric_dd, t0_txt, t1_txt, btn_run, out_all)\n",
    "\n",
    "# ---------------- main action ----------------\n",
    "def _one_variable_plot(key, cm, metric, t0, t1):\n",
    "    vb, ve, vi = cm[key][\"bmd\"], cm[key][\"era5\"], cm[key][\"imerg\"]\n",
    "    # sanity\n",
    "    for src, ds, vn in [(\"BMD\", ds_bmd, vb), (\"ERA5\", ds_era5, ve)]:\n",
    "        if vn is None or vn not in ds.data_vars:\n",
    "            display(Markdown(f\"❌ **{src} variable not found**: `{vn}` for `{key}`\")); \n",
    "            return\n",
    "\n",
    "    has_imerg = (\"ds_imerg\" in globals()) and (ds_imerg is not None) and (vi is not None) and (vi in ds_imerg.data_vars)\n",
    "\n",
    "    truth = _norm(key, ds_bmd[vb]).sel(time=slice(t0, t1))\n",
    "    era5  = _norm(key, ds_era5[ve]).sel(time=slice(t0, t1))\n",
    "    imerg = _norm(key, ds_imerg[vi]).sel(time=slice(t0, t1)) if has_imerg else None\n",
    "    if truth.sizes.get(\"time\",0) == 0:\n",
    "        display(Markdown(f\"⚠️ **No BMD data** for {LABELS[key]} in this window.\")); \n",
    "        return\n",
    "\n",
    "    truth = _ensure_valid_time(truth)\n",
    "    era5  = _ensure_valid_time(era5)\n",
    "    if imerg is not None:\n",
    "        imerg = _ensure_valid_time(imerg)\n",
    "\n",
    "    era5_on = _align_to_truth(era5, truth)\n",
    "    imerg_on = _align_to_truth(imerg, truth) if imerg is not None else None\n",
    "\n",
    "    # common overlap\n",
    "    tmin = max(np.datetime64(truth.valid_time.min().values),\n",
    "               np.datetime64(era5_on.valid_time.min().values))\n",
    "    tmax = min(np.datetime64(truth.valid_time.max().values),\n",
    "               np.datetime64(era5_on.valid_time.max().values))\n",
    "    if imerg_on is not None:\n",
    "        tmin = max(tmin, np.datetime64(imerg_on.valid_time.min().values))\n",
    "        tmax = min(tmax, np.datetime64(imerg_on.valid_time.max().values))\n",
    "\n",
    "    truth_c = truth.sel(valid_time=slice(tmin, tmax))\n",
    "    era5_c  = era5_on.sel(valid_time=slice(tmin, tmax))\n",
    "    imerg_c = imerg_on.sel(valid_time=slice(tmin, tmax)) if imerg_on is not None else None\n",
    "    if truth_c.sizes.get(\"valid_time\",0) == 0:\n",
    "        display(Markdown(f\"⚠️ **No overlapping days** for {LABELS[key]}.\")); \n",
    "        return\n",
    "\n",
    "    # ocean mask by BMD coverage\n",
    "    if imerg_c is not None:\n",
    "        truth_m, era5_m, imerg_m = _mask_to_truth(truth_c, era5_c, imerg_c)\n",
    "    else:\n",
    "        truth_m, era5_m = _mask_to_truth(truth_c, era5_c)\n",
    "\n",
    "    # compute series\n",
    "    if metric == \"RMSE\":\n",
    "        s_era5, _ = _rmse_mae_series(era5_m, truth_m); ylabel = \"RMSE\"\n",
    "    else:\n",
    "        _, s_era5 = _rmse_mae_series(era5_m, truth_m); ylabel = \"MAE\"\n",
    "\n",
    "    nrows = 2 if imerg_c is not None else 1\n",
    "    fig, axs = plt.subplots(nrows, 1, figsize=(10, 6 if nrows==2 else 3), sharex=True)\n",
    "\n",
    "    ax0 = axs[0] if nrows==2 else axs\n",
    "    s_era5.rename({\"valid_time\":\"date\"}).plot(ax=ax0)\n",
    "    ax0.set_title(f\"{ylabel} — ERA5 vs BMD — { (vb if key!='precip' else 'total_precipitation_24hr') }\")\n",
    "    ax0.set_ylabel(\"mm/day\" if key==\"precip\" else \"K\")\n",
    "    ax0.grid(True, alpha=0.3)\n",
    "\n",
    "    if nrows == 2:\n",
    "        if metric == \"RMSE\":\n",
    "            s_imerg, _ = _rmse_mae_series(imerg_m, truth_m)\n",
    "        else:\n",
    "            _, s_imerg = _rmse_mae_series(imerg_m, truth_m)\n",
    "        axs[1].plot(s_imerg[\"valid_time\"].values, s_imerg.values)\n",
    "        axs[1].set_title(f\"{ylabel} — IMERG vs BMD — { (vi if key!='precip' else 'total_precipitation_24hr') }\")\n",
    "        axs[1].set_ylabel(\"mm/day\" if key==\"precip\" else \"K\")\n",
    "        axs[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # print window means\n",
    "    try:\n",
    "        mean_era5 = float(s_era5.mean().values)\n",
    "        unit = \"mm/day\" if key==\"precip\" else \"K\"\n",
    "        if nrows == 2:\n",
    "            mean_imerg = float(s_imerg.mean().values)\n",
    "            display(Markdown(f\"**Window mean {ylabel}** — ERA5: `{mean_era5:.3f} {unit}` | IMERG: `{mean_imerg:.3f} {unit}`\"))\n",
    "        else:\n",
    "            display(Markdown(f\"**Window mean {ylabel}** — ERA5: `{mean_era5:.3f} {unit}` (IMERG not available)\"))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def _run_all(_):\n",
    "    with out_all:\n",
    "        out_all.clear_output()\n",
    "        cm = _current_mapping()\n",
    "        keys = _plottable_vars(cm)\n",
    "        if not keys:\n",
    "            display(Markdown(\"❌ No variables available in **both** BMD and ERA5. Adjust overrides above.\")); \n",
    "            return\n",
    "        metric = metric_dd.value\n",
    "        t0 = np.datetime64(t0_txt.value)\n",
    "        t1 = np.datetime64(t1_txt.value)\n",
    "        display(Markdown(f\"**Running** {', '.join(LABELS[k] for k in keys)}  \\n\"\n",
    "                         f\"Metric: `{metric}` — Window: `{str(t0)}` → `{str(t1)}`\"))\n",
    "        for k in keys:\n",
    "            display(Markdown(f\"### {LABELS[k]}\"))\n",
    "            _one_variable_plot(k, cm, metric, t0, t1)\n",
    "\n",
    "btn_run.on_click(_run_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bcecb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3509ae95fb4a64ae19963f15819cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Region:', options=('Global', 'Ethiopia', 'Nigeria', 'Kenya', 'Bangladesh', 'Chile'), val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626e9cb91519458691c2cfb67ad0e166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Metric:', options=('RMSE', 'MAE'), value='RMSE')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "212cd6c71e1f4b1481dafc11723a7810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='2018-06-01', description='Start (YYYY-MM-DD):')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4569dbbb48b6433da395ac96cfc75d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='2018-06-30', description='End   (YYYY-MM-DD):')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbdbb8911fb14a158be2b95edc90796f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Run (IMD truth)', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92be41e8c9d4be9b8608c241b92569d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Cell 2: IMD truth — ERA5 & IMERG (precip only), multi-region ===\n",
    "import numpy as np, xarray as xr, matplotlib.pyplot as plt, ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "plt.rcParams.update({\"figure.dpi\": 120})\n",
    "\n",
    "VAR = \"total_precipitation_24hr\"\n",
    "REGIONS = {\n",
    "    \"Global\":     {\"latitude\": slice(-90, 90),  \"longitude\": slice(0, 360)},\n",
    "    \"Ethiopia\":   {\"latitude\": slice(3.4, 14.9),\"longitude\": slice(33.0, 48.0)},\n",
    "    \"Nigeria\":    {\"latitude\": slice(4.0, 14.7),\"longitude\": slice(2.7, 14.7)},\n",
    "    \"Kenya\":      {\"latitude\": slice(-4.7, 5.0),\"longitude\": slice(33.9, 41.9)},\n",
    "    \"Bangladesh\": {\"latitude\": slice(20.7, 26.7),\"longitude\": slice(88.0, 92.7)},\n",
    "    \"Chile\":      {\"latitude\": slice(-56.0, -17.5),\"longitude\": slice(284.0, 294.0)},\n",
    "}\n",
    "\n",
    "def _norm_mm(da):\n",
    "    u = (da.attrs.get(\"units\") or da.attrs.get(\"unit\") or \"\").lower()\n",
    "    if u in [\"m\",\"meter\",\"metre\",\"m of water equivalent\"]:\n",
    "        da = da * 1000.0\n",
    "    da.attrs[\"units\"] = \"mm\"\n",
    "    return da\n",
    "\n",
    "def _ensure_valid_time(da):\n",
    "    if \"valid_time\" in da.dims: return da\n",
    "    if \"time\" in da.dims:       return da.rename({\"time\":\"valid_time\"})\n",
    "    dec = xr.decode_cf(da.to_dataset(name=\"_tmp\"), use_cftime=False).to_array(\"_tmp\")\n",
    "    if \"time\" in dec.dims:      return dec.rename({\"time\":\"valid_time\"})\n",
    "    raise ValueError(\"No time/valid_time dimension.\")\n",
    "\n",
    "def _apply_region(ds, region):\n",
    "    lat_lo = min(region[\"latitude\"].start,  region[\"latitude\"].stop)\n",
    "    lat_hi = max(region[\"latitude\"].start,  region[\"latitude\"].stop)\n",
    "    lon_lo = min(region[\"longitude\"].start, region[\"longitude\"].stop)\n",
    "    lon_hi = max(region[\"longitude\"].start, region[\"longitude\"].stop)\n",
    "    return ds.sel(latitude=slice(lat_lo, lat_hi), longitude=slice(lon_lo, lon_hi))\n",
    "\n",
    "def _align_to_truth(src, truth):\n",
    "    s = src.sortby([\"latitude\",\"longitude\"]); r = truth.sortby([\"latitude\",\"longitude\"])\n",
    "    try:\n",
    "        return s.reindex_like(r, method=\"nearest\",\n",
    "                              tolerance={\"latitude\":0.125,\"longitude\":0.125})\n",
    "    except Exception:\n",
    "        return s.interp(latitude=r.latitude, longitude=r.longitude, method=\"nearest\")\n",
    "\n",
    "def _rmse_mae_series(pred, truth):\n",
    "    diff = (pred - truth).astype(\"float32\")\n",
    "    se, ae = diff**2, np.abs(diff)\n",
    "    rmse = se.mean([d for d in (\"latitude\",\"longitude\") if d in se.dims], skipna=True)**0.5\n",
    "    mae  = ae.mean([d for d in (\"latitude\",\"longitude\") if d in ae.dims],  skipna=True)\n",
    "    return rmse.squeeze(), mae.squeeze()\n",
    "\n",
    "def _mask_to_truth(truth, *others):\n",
    "    m = xr.ufuncs.isfinite(truth).any(\"valid_time\")\n",
    "    outs = [truth.where(m)] + [o.where(m) for o in others]\n",
    "    return outs\n",
    "\n",
    "# ── UI ───────────────────────────────────────────────────────────────────────\n",
    "region_dd = widgets.Dropdown(options=list(REGIONS.keys()), description=\"Region:\", value=\"Global\")\n",
    "metric_dd = widgets.Dropdown(options=[\"RMSE\",\"MAE\"], description=\"Metric:\", value=\"RMSE\")\n",
    "t0_txt    = widgets.Text(value=\"2018-06-01\", description=\"Start (YYYY-MM-DD):\")\n",
    "t1_txt    = widgets.Text(value=\"2018-06-30\", description=\"End   (YYYY-MM-DD):\")\n",
    "btn_run2  = widgets.Button(description=\"Run (IMD truth)\", button_style=\"success\")\n",
    "out_imd   = widgets.Output()\n",
    "display(region_dd, metric_dd, t0_txt, t1_txt, btn_run2, out_imd)\n",
    "\n",
    "def run_imd(_):\n",
    "    with out_imd:\n",
    "        out_imd.clear_output()\n",
    "\n",
    "        # availability\n",
    "        if (VAR not in ds_imd) or (VAR not in ds_era5):\n",
    "            print(f\"❌ '{VAR}' missing in IMD or ERA5.\"); return\n",
    "        has_imerg_candidate = ('ds_imerg' in globals()) and (ds_imerg is not None) and (VAR in ds_imerg)\n",
    "\n",
    "        region = REGIONS[region_dd.value]\n",
    "        t0 = np.datetime64(t0_txt.value); t1 = np.datetime64(t1_txt.value)\n",
    "\n",
    "        truth = _norm_mm(_apply_region(ds_imd [[VAR]], region)[VAR]).sel(time=slice(t0,t1))\n",
    "        era5  = _norm_mm(_apply_region(ds_era5[[VAR]], region)[VAR]).sel(time=slice(t0,t1))\n",
    "        imerg = _norm_mm(_apply_region(ds_imerg[[VAR]], region)[VAR]).sel(time=slice(t0,t1)) if has_imerg_candidate else None\n",
    "        if truth.sizes.get(\"time\",0)==0:\n",
    "            print(\"⚠️ IMD empty in this window/region.\"); return\n",
    "\n",
    "        truth = _ensure_valid_time(truth)\n",
    "        era5  = _ensure_valid_time(era5)\n",
    "        if imerg is not None:\n",
    "            imerg = _ensure_valid_time(imerg)\n",
    "\n",
    "        era5_on  = _align_to_truth(era5, truth)\n",
    "        imerg_on = _align_to_truth(imerg, truth) if imerg is not None else None\n",
    "\n",
    "        # intersect time\n",
    "        tmin = max(np.datetime64(truth.valid_time.min().values),\n",
    "                   np.datetime64(era5_on.valid_time.min().values))\n",
    "        tmax = min(np.datetime64(truth.valid_time.max().values),\n",
    "                   np.datetime64(era5_on.valid_time.max().values))\n",
    "        if imerg_on is not None:\n",
    "            tmin = max(tmin, np.datetime64(imerg_on.valid_time.min().values))\n",
    "            tmax = min(tmax, np.datetime64(imerg_on.valid_time.max().values))\n",
    "\n",
    "        truth_c = truth.sel(valid_time=slice(tmin, tmax))\n",
    "        era5_c  = era5_on.sel(valid_time=slice(tmin, tmax))\n",
    "        imerg_c = imerg_on.sel(valid_time=slice(tmin, tmax)) if imerg_on is not None else None\n",
    "        if truth_c.sizes.get(\"valid_time\",0)==0:\n",
    "            print(\"⚠️ No overlap among datasets.\"); return\n",
    "\n",
    "        # mask ocean via IMD coverage\n",
    "        if imerg_c is not None:\n",
    "            truth_m, era5_m, imerg_m = _mask_to_truth(truth_c, era5_c, imerg_c)\n",
    "        else:\n",
    "            truth_m, era5_m = _mask_to_truth(truth_c, era5_c)\n",
    "\n",
    "        # if IMERG ended up empty after masking/intersection, drop the bottom panel\n",
    "        imerg_valid = (imerg_c is not None) and (imerg_m.sizes.get(\"valid_time\",0) > 0)\n",
    "\n",
    "        metric = metric_dd.value\n",
    "        nrows = 2 if imerg_valid else 1\n",
    "        fig, axs = plt.subplots(nrows, 1, figsize=(10, 6 if nrows==2 else 3), sharex=True)\n",
    "\n",
    "        if metric == \"RMSE\":\n",
    "            s_era5, _ = _rmse_mae_series(era5_m, truth_m); ylabel = \"RMSE (mm/day)\"\n",
    "        else:\n",
    "            _, s_era5 = _rmse_mae_series(era5_m, truth_m); ylabel = \"MAE (mm/day)\"\n",
    "\n",
    "        ax0 = axs[0] if nrows==2 else axs\n",
    "        s_era5.rename({\"valid_time\":\"date\"}).plot(ax=ax0)\n",
    "        ax0.set_title(f\"{ylabel} — ERA5 vs IMD — {VAR} — {region_dd.value}\")\n",
    "        ax0.set_ylabel(\"mm/day\")\n",
    "        ax0.grid(True, alpha=0.3)\n",
    "\n",
    "        if imerg_valid:\n",
    "            if metric == \"RMSE\":\n",
    "                s_imerg, _ = _rmse_mae_series(imerg_m, truth_m)\n",
    "            else:\n",
    "                _, s_imerg = _rmse_mae_series(imerg_m, truth_m)\n",
    "            axs[1].plot(s_imerg[\"valid_time\"].values, s_imerg.values)\n",
    "            axs[1].set_title(f\"{ylabel} — IMERG vs IMD — {VAR} — {region_dd.value}\")\n",
    "            axs[1].set_ylabel(\"mm/day\")\n",
    "            axs[1].grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "btn_run2.on_click(run_imd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f73db1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Spatial bias maps — IMD truth (May–July, mean over years)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f60efeb61374c47a9880b21dfdec157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='2018-2021', description='Years (YYYY–YYYY):'), Checkbox(value=True, description='Sm…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025789a0071a43eaa7306f530f2c9cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Bias-map UI ready. Click **Run bias maps**.\n"
     ]
    }
   ],
   "source": [
    "# Cell — Bias maps over India (IMD truth) with safe widget creation & wiring\n",
    "import numpy as np, pandas as pd, xarray as xr, matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# ---------- Use existing datasets if present ----------\n",
    "try: ds_imd\n",
    "except NameError: ds_imd = None\n",
    "try: ds_imerg\n",
    "except NameError: ds_imerg = None\n",
    "try: ds_e5_p   # ERA5 daily precip\n",
    "except NameError: ds_e5_p = None\n",
    "\n",
    "VAR = \"total_precipitation_24hr\"   # precipitation variable in all three\n",
    "\n",
    "# ---------- Minimal helpers (self-contained) ----------\n",
    "def _normalize_mm(da):\n",
    "    units = (da.attrs.get(\"units\") or da.attrs.get(\"unit\") or \"\").lower()\n",
    "    out = da\n",
    "    if units in [\"m\",\"meter\",\"metre\",\"m of water equivalent\"]:\n",
    "        out = out * 1000.0\n",
    "    out.attrs[\"units\"] = \"mm\"\n",
    "    return out\n",
    "\n",
    "def _to_0360(obj):\n",
    "    if \"longitude\" in obj.coords:\n",
    "        lon = obj[\"longitude\"]\n",
    "        try:\n",
    "            if float(lon.min()) < 0:\n",
    "                obj = obj.assign_coords(longitude=(lon % 360))\n",
    "        except Exception:\n",
    "            pass\n",
    "        obj = obj.sortby(\"longitude\")\n",
    "    return obj\n",
    "\n",
    "def _ensure_lat_asc(obj):\n",
    "    if \"latitude\" in obj.coords:\n",
    "        lat = obj[\"latitude\"].values\n",
    "        if len(lat) > 1 and lat[0] > lat[-1]:\n",
    "            obj = obj.sortby(\"latitude\")\n",
    "    return obj\n",
    "\n",
    "def _coerce_time(da):\n",
    "    if \"time\" in da.dims: return da\n",
    "    # try CF decode\n",
    "    dec = xr.decode_cf(da.to_dataset(name=\"_tmp\")).to_array(\"_tmp\")\n",
    "    if \"time\" in dec.dims: return dec\n",
    "    raise ValueError(\"No time dimension.\")\n",
    "\n",
    "def _align_to_reference_grid(src: xr.DataArray, ref: xr.DataArray) -> xr.DataArray:\n",
    "    \"\"\"Nearest-label reindex then nearest interp; avoids empty-grid crashes.\"\"\"\n",
    "    # early guards\n",
    "    if src.sizes.get(\"latitude\",0)==0 or src.sizes.get(\"longitude\",0)==0:\n",
    "        return src\n",
    "    if ref.sizes.get(\"latitude\",0)==0 or ref.sizes.get(\"longitude\",0)==0:\n",
    "        raise RuntimeError(\"reference grid has zero points (lat or lon size = 0).\")\n",
    "    s = _ensure_lat_asc(_to_0360(src))\n",
    "    r = _ensure_lat_asc(_to_0360(ref))\n",
    "    # identical labels?\n",
    "    try:\n",
    "        if np.array_equal(s.latitude.values, r.latitude.values) and np.array_equal(s.longitude.values, r.longitude.values):\n",
    "            return s\n",
    "    except Exception:\n",
    "        pass\n",
    "    # safe nearest label reindex\n",
    "    try:\n",
    "        return s.reindex_like(r, method=\"nearest\", tolerance={\"latitude\":0.125,\"longitude\":0.125})\n",
    "    except Exception:\n",
    "        pass\n",
    "    # fallback nearest interp\n",
    "    s2 = s.sortby([\"latitude\",\"longitude\"])\n",
    "    r2 = r.sortby([\"latitude\",\"longitude\"])\n",
    "    return s2.interp(latitude=r2[\"latitude\"], longitude=r2[\"longitude\"], method=\"nearest\")\n",
    "\n",
    "def _india_box_from_imd(imd_da: xr.DataArray):\n",
    "    \"\"\"Compute lat/lon bounds from where IMD is ever finite.\"\"\"\n",
    "    mask_any = xr.ufuncs.isfinite(imd_da).any(\"time\")\n",
    "    lat_any = mask_any.any(\"longitude\")\n",
    "    lon_any = mask_any.any(\"latitude\")\n",
    "    # dask-safe: compute boolean indexers\n",
    "    lat_vals = imd_da.latitude.where(lat_any).dropna(\"latitude\")\n",
    "    lon_vals = imd_da.longitude.where(lon_any).dropna(\"longitude\")\n",
    "    if lat_vals.size == 0 or lon_vals.size == 0:\n",
    "        # fallback box\n",
    "        return 6.5, 37.0, 68.0, 98.0\n",
    "    return float(lat_vals.min()), float(lat_vals.max()), float(lon_vals.min()), float(lon_vals.max())\n",
    "\n",
    "def _slice_box(da, lat0, lat1, lon0, lon1):\n",
    "    lo = min(lon0%360, lon1%360); hi = max(lon0%360, lon1%360)\n",
    "    lat_lo = min(lat0, lat1);     lat_hi = max(lat0, lat1)\n",
    "    da1 = _ensure_lat_asc(_to_0360(da))\n",
    "    return da1.sel(latitude=slice(lat_lo, lat_hi), longitude=slice(lo, hi))\n",
    "\n",
    "def _time_filter_mjj_and_years(da, years):\n",
    "    da = da.sel(time=da.time.dt.month.isin([5,6,7]))\n",
    "    if years:\n",
    "        y0, y1 = years\n",
    "        da = da.sel(time=slice(f\"{y0}-01-01\", f\"{y1}-12-31\"))\n",
    "    return da\n",
    "\n",
    "# ---------- Widgets (create if missing) ----------\n",
    "try: btn_run_map\n",
    "except NameError:\n",
    "    btn_run_map = widgets.Button(description=\"Run bias maps\", button_style=\"info\")\n",
    "\n",
    "try: years_txt\n",
    "except NameError:\n",
    "    years_txt = widgets.Text(value=\"2018-2021\", description=\"Years (YYYY-YYYY):\")\n",
    "\n",
    "try: smooth_chk\n",
    "except NameError:\n",
    "    smooth_chk = widgets.Checkbox(value=True, description=\"Smooth (gaussian)\")\n",
    "\n",
    "try: vmax_txt\n",
    "except NameError:\n",
    "    vmax_txt = widgets.Text(value=\"50\", description=\"Abs max (mm)\")\n",
    "\n",
    "try: show_era5\n",
    "except NameError:\n",
    "    show_era5 = widgets.Checkbox(value=True, description=\"ERA5 vs IMD\")\n",
    "\n",
    "try: show_imerg\n",
    "except NameError:\n",
    "    show_imerg = widgets.Checkbox(value=True, description=\"IMERG vs IMD\")\n",
    "\n",
    "try: out_map\n",
    "except NameError:\n",
    "    out_map = widgets.Output()\n",
    "\n",
    "ui = widgets.HBox([years_txt, smooth_chk, vmax_txt, show_era5, show_imerg, btn_run_map])\n",
    "display(Markdown(\"### Spatial bias maps — IMD truth (May–July, mean over years)\"))\n",
    "display(ui, out_map)\n",
    "\n",
    "# ---------- Bias-map runner ----------\n",
    "def run_bias_maps(_):\n",
    "    with out_map:\n",
    "        out_map.clear_output()\n",
    "        # sanity\n",
    "        if ds_imd is None or ds_e5_p is None or ds_imerg is None:\n",
    "            print(\"❌ Please load IMD, ERA5 (precip), and IMERG datasets first.\")\n",
    "            return\n",
    "        if VAR not in ds_imd or VAR not in ds_e5_p or VAR not in ds_imerg:\n",
    "            print(f\"❌ `{VAR}` must exist in all datasets.\")\n",
    "            return\n",
    "\n",
    "        # parse years\n",
    "        yrs = years_txt.value.strip()\n",
    "        years = None\n",
    "        if yrs:\n",
    "            try:\n",
    "                a, b = yrs.split(\"-\")\n",
    "                years = (int(a), int(b))\n",
    "            except Exception:\n",
    "                print(\"⚠️ Could not parse years; using full overlap.\")\n",
    "\n",
    "        print(\"Step 1/7: Prepping variables …\")\n",
    "        imd   = _normalize_mm(_coerce_time(ds_imd[VAR]))\n",
    "        imerg = _normalize_mm(_coerce_time(ds_imerg[VAR]))\n",
    "        era5  = _normalize_mm(_coerce_time(ds_e5_p[VAR]))\n",
    "\n",
    "        print(\"Step 2/7: Building dynamic India box from IMD coverage …\")\n",
    "        lat0, lat1, lon0, lon1 = _india_box_from_imd(imd)\n",
    "        print(f\"  India box (lat, lon): [{lat0:.2f}, {lat1:.2f}] × [{lon0:.2f}, {lon1:.2f}]\")\n",
    "\n",
    "        print(\"Step 3/7: Slicing all products to the India box …\")\n",
    "        imd_ind   = _slice_box(imd,   lat0, lat1, lon0, lon1)\n",
    "        imerg_ind = _slice_box(imerg, lat0, lat1, lon0, lon1)\n",
    "        era5_ind  = _slice_box(era5,  lat0, lat1, lon0, lon1)\n",
    "        def _ext(da):\n",
    "            return (float(da.latitude.min()), float(da.latitude.max()),\n",
    "                    float(da.longitude.min()), float(da.longitude.max()),\n",
    "                    str(pd.to_datetime(da.time.min().values).date()),\n",
    "                    str(pd.to_datetime(da.time.max().values).date()),\n",
    "                    int(da.sizes.get(\"time\",0)))\n",
    "        la0, la1, lo0, lo1, tmin, tmax, tn = _ext(imd_ind)\n",
    "        print(f\"  IMD   lat: {la0:.2f} … {la1:.2f}  |  lon: {lo0:.2f} … {lo1:.2f}  |  time: {tmin} … {tmax} (n={tn})\")\n",
    "\n",
    "        la0, la1, lo0, lo1, tmin, tmax, tn = _ext(imerg_ind)\n",
    "        print(f\"  IMERG lat: {la0:.2f} … {la1:.2f}  |  lon: {lo0:.2f} … {lo1:.2f}  |  time: {tmin} … {tmax} (n={tn})\")\n",
    "\n",
    "        la0, la1, lo0, lo1, tmin, tmax, tn = _ext(era5_ind)\n",
    "        print(f\"  ERA5  lat: {la0:.2f} … {la1:.2f}  |  lon: {lo0:.2f} … {lo1:.2f}  |  time: {tmin} … {tmax} (n={tn})\")\n",
    "\n",
    "        print(\"Step 4/7: Selecting May–July and requested years …\")\n",
    "        imd_mjj   = _time_filter_mjj_and_years(imd_ind, years)\n",
    "        imerg_mjj = _time_filter_mjj_and_years(imerg_ind, years)\n",
    "        era5_mjj  = _time_filter_mjj_and_years(era5_ind, years)\n",
    "\n",
    "        # intersect time range across all three\n",
    "        t0 = max(np.datetime64(imd_mjj.time.min().values),\n",
    "                 np.datetime64(imerg_mjj.time.min().values),\n",
    "                 np.datetime64(era5_mjj.time.min().values))\n",
    "        t1 = min(np.datetime64(imd_mjj.time.max().values),\n",
    "                 np.datetime64(imerg_mjj.time.max().values),\n",
    "                 np.datetime64(era5_mjj.time.max().values))\n",
    "        imd_mjj   = imd_mjj.sel(time=slice(t0, t1))\n",
    "        imerg_mjj = imerg_mjj.sel(time=slice(t0, t1))\n",
    "        era5_mjj  = era5_mjj.sel(time=slice(t0, t1))\n",
    "\n",
    "        print(\"Step 5/7: Aligning IMERG/ERA5 to IMD grid …\")\n",
    "        try:\n",
    "            imerg_on_imd = _align_to_reference_grid(imerg_mjj, imd_mjj)\n",
    "            era5_on_imd  = _align_to_reference_grid(era5_mjj,  imd_mjj)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Align error: {e}\"); return\n",
    "\n",
    "        print(\"Step 6/7: Intersecting time …\")\n",
    "        # re-check common time after alignment (labels retained)\n",
    "        t0 = max(np.datetime64(imd_mjj.time.min().values),\n",
    "                 np.datetime64(imerg_on_imd.time.min().values),\n",
    "                 np.datetime64(era5_on_imd.time.min().values))\n",
    "        t1 = min(np.datetime64(imd_mjj.time.max().values),\n",
    "                 np.datetime64(imerg_on_imd.time.max().values),\n",
    "                 np.datetime64(era5_on_imd.time.max().values))\n",
    "        imd_use   = imd_mjj.sel(time=slice(t0, t1))\n",
    "        imerg_use = imerg_on_imd.sel(time=slice(t0, t1))\n",
    "        era5_use  = era5_on_imd.sel(time=slice(t0, t1))\n",
    "\n",
    "        print(\"Step 7/7: Computing time-mean bias (May–July, selected years) …\")\n",
    "        # mask: finite anywhere in window (land/coverage)\n",
    "        m_imd = xr.ufuncs.isfinite(imd_use).any(\"time\")\n",
    "        # predictors masked to IMD coverage\n",
    "        imerg_bias = (imerg_use - imd_use).where(m_imd).mean(\"time\", skipna=True)\n",
    "        era5_bias  = (era5_use  - imd_use).where(m_imd).mean(\"time\", skipna=True)\n",
    "\n",
    "        # optional smoothing\n",
    "        if smooth_chk.value:\n",
    "            try:\n",
    "                from scipy.ndimage import gaussian_filter\n",
    "                imerg_bias_vals = gaussian_filter(np.asarray(imerg_bias), sigma=0.8, mode=\"nearest\")\n",
    "                era5_bias_vals  = gaussian_filter(np.asarray(era5_bias),  sigma=0.8, mode=\"nearest\")\n",
    "            except Exception:\n",
    "                imerg_bias_vals = np.asarray(imerg_bias)\n",
    "                era5_bias_vals  = np.asarray(era5_bias)\n",
    "        else:\n",
    "            imerg_bias_vals = np.asarray(imerg_bias)\n",
    "            era5_bias_vals  = np.asarray(era5_bias)\n",
    "\n",
    "        # plotting\n",
    "        vmax = float(vmax_txt.value or 50)\n",
    "        vmin = -vmax\n",
    "        ncols = int(show_era5.value) + int(show_imerg.value)\n",
    "        if ncols == 0:\n",
    "            print(\"⚠️ Select at least one predictor to plot.\"); return\n",
    "        fig, axs = plt.subplots(1, ncols, figsize=(5.8*ncols, 5), constrained_layout=True)\n",
    "        if ncols == 1: axs = [axs]\n",
    "\n",
    "        i = 0\n",
    "        if show_era5.value:\n",
    "            im0 = axs[i].imshow(era5_bias_vals, origin=\"lower\",\n",
    "                                extent=[float(imd_use.longitude.min()), float(imd_use.longitude.max()),\n",
    "                                        float(imd_use.latitude.min()),  float(imd_use.latitude.max())],\n",
    "                                vmin=vmin, vmax=vmax, cmap=\"RdBu_r\", aspect=\"auto\")\n",
    "            axs[i].set_title(\"Bias: ERA5 − IMD (mm/day)\")\n",
    "            axs[i].set_xlabel(\"Longitude\"); axs[i].set_ylabel(\"Latitude\")\n",
    "            fig.colorbar(im0, ax=axs[i], fraction=0.046, pad=0.04, label=\"mm/day\")\n",
    "            i += 1\n",
    "\n",
    "        if show_imerg.value:\n",
    "            im1 = axs[i].imshow(imerg_bias_vals, origin=\"lower\",\n",
    "                                extent=[float(imd_use.longitude.min()), float(imd_use.longitude.max()),\n",
    "                                        float(imd_use.latitude.min()),  float(imd_use.latitude.max())],\n",
    "                                vmin=vmin, vmax=vmax, cmap=\"RdBu_r\", aspect=\"auto\")\n",
    "            axs[i].set_title(\"Bias: IMERG − IMD (mm/day)\")\n",
    "            axs[i].set_xlabel(\"Longitude\"); axs[i].set_ylabel(\"Latitude\")\n",
    "            fig.colorbar(im1, ax=axs[i], fraction=0.046, pad=0.04, label=\"mm/day\")\n",
    "\n",
    "        # caption\n",
    "        y0 = pd.to_datetime(str(imd_use.time.min().values)).year\n",
    "        y1 = pd.to_datetime(str(imd_use.time.max().values)).year\n",
    "        display(Markdown(f\"*Mean bias over **May–July**, years **{y0}–{y1}**; masked to IMD coverage (ocean excluded).*\"))\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# ---------- Wire the button (idempotent) ----------\n",
    "btn_run_map.on_click(run_bias_maps)\n",
    "print(\"✅ Bias-map UI ready. Click **Run bias maps**.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIFS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
